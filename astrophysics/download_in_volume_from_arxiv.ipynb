{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T03:46:32.670345Z",
     "start_time": "2020-02-24T03:46:32.663792Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `urllib`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [arxiv.py](https://github.com/lukasschwab/arxiv.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T03:46:35.010631Z",
     "start_time": "2020-02-24T03:46:34.756234Z"
    }
   },
   "outputs": [],
   "source": [
    "from requests.exceptions import HTTPError\n",
    "from urllib.parse import urlencode\n",
    "from urllib.request import urlretrieve\n",
    "import feedparser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(search_query=\"\",\n",
    "          id_list=[],\n",
    "          prune=True,\n",
    "          start=0,\n",
    "          max_results=10,\n",
    "          sort_by=\"relevance\",\n",
    "          sort_order=\"descending\"):\n",
    "    url_args = urlencode({\n",
    "        \"search_query\": search_query,\n",
    "        \"id_list\": ','.join(id_list),\n",
    "        \"start\": start,\n",
    "        \"max_results\": max_results,\n",
    "        \"sortBy\": sort_by,\n",
    "        \"sortOrder\": sort_order\n",
    "    })\n",
    "    results = feedparser.parse(root_url + 'query?' + url_args)\n",
    "    # results is a atom feed atomxxx.xml. Might be a dictionary, what will  feedparser.parse(xxxurl) return\n",
    "    if results.get('status') != 200:\n",
    "        # TODO: better error reporting\n",
    "        raise Exception(\"HTTP Error \" +\n",
    "                        str(results.get('status', 'no status')) + \" in query\")\n",
    "    else:\n",
    "        results = results['entries']\n",
    "    results = [r for r in results if r.get(\"title\", None)]\n",
    "    for result in results:\n",
    "        mod_query_result(result)\n",
    "        if prune:\n",
    "            prune_query_result(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_query_result(result):\n",
    "    # Useful to have for download automation\n",
    "    result['pdf_url'] = None\n",
    "    for link in result['links']:\n",
    "        if 'title' in link and link['title'] == 'pdf':\n",
    "            result['pdf_url'] = link['href']\n",
    "    result['affiliation'] = result.pop('arxiv_affiliation', 'None')\n",
    "    result['arxiv_url'] = result.pop('link')\n",
    "    result['title'] = result['title'].rstrip('\\n')\n",
    "    result['summary'] = result['summary'].rstrip('\\n')\n",
    "    result['authors'] = [d['name'] for d in result['authors']]\n",
    "    if 'arxiv_comment' in result:\n",
    "        result['arxiv_comment'] = result['arxiv_comment'].rstrip('\\n')\n",
    "    else:\n",
    "        result['arxiv_comment'] = None\n",
    "    if 'arxiv_journal_ref' in result:\n",
    "        result['journal_reference'] = result.pop('arxiv_journal_ref')\n",
    "    else:\n",
    "        result['journal_reference'] = None\n",
    "    if 'arxiv_doi' in result:\n",
    "        result['doi'] = result.pop('arxiv_doi')\n",
    "    else:\n",
    "        result['doi'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].pop('arxiv_affiliation', 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_query_result(result):\n",
    "    prune_keys = ['updated_parsed',\n",
    "                  'published_parsed',\n",
    "                  'arxiv_primary_category',\n",
    "                  'summary_detail',\n",
    "                  'author',\n",
    "                  'author_detail',\n",
    "                  'links',\n",
    "                  'guidislink',\n",
    "                  'title_detail',\n",
    "                  'tags',\n",
    "                  'id']\n",
    "    for key in prune_keys:\n",
    "        try:\n",
    "            del result['key']\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slugify(obj):\n",
    "    # Remove special characters from object title\n",
    "    filename = '_'.join(re.findall(r'\\w+', obj.get('title', 'UNTITLED')))\n",
    "    # Prepend object id\n",
    "    filename = \"%s.%s\" % (obj.get('pdf_url').split('/')[-1], filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(obj, dirpath='./', slugify=slugify):\n",
    "    if not obj.get('pdf_url', ''):\n",
    "        print(\"Object has no PDF URL.\")\n",
    "        return\n",
    "    if dirpath[-1] != '/':\n",
    "        dirpath += '/'\n",
    "    path = dirpath + slugify(obj) + '.pdf'\n",
    "    urlretrieve(obj['pdf_url'], path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = query(id_list=[\"1707.08567\"])\n",
    "download(paper) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `requests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T04:18:38.917296Z",
     "start_time": "2020-02-24T04:18:37.887139Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T10:17:04.859285Z",
     "start_time": "2020-02-24T10:17:04.855755Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/wm/Playground/IdealOps/batch_jobs/data/data_sample/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T10:24:32.067462Z",
     "start_time": "2020-02-24T10:24:32.055391Z"
    }
   },
   "outputs": [],
   "source": [
    "with open (data_path + 'norm_trend.json') as  f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T09:43:02.431078Z",
     "start_time": "2020-02-25T09:43:02.423871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://baike.baidu.com/search/word?word=%20%20%20mama\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    " \n",
    "word='   mama'\n",
    "word=urllib.parse.quote(word)\n",
    "url='https://baike.baidu.com/search/word?word=%s'%word\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angs = {'japanese': 'ja',\n",
    "         'english': 'en'}\n",
    "\n",
    "def get_sound_file_for_text(text, download=False, lang='japanese'):\n",
    "\n",
    "    r = StringIO()\n",
    "    glang = langs[lang]\n",
    "    text = text.replace('*', '')\n",
    "    text = text.replace('/', '')\n",
    "    text = text.replace('x', '')\n",
    "    url = 'http://translate.google.com/translate_tts'\n",
    "    if download:\n",
    "        result = requests.get(url, params={'tl': glang, 'q': text})\n",
    "        r.write(result.content)\n",
    "        r.seek(0)\n",
    "        return r\n",
    "    else:\n",
    "        return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T09:42:02.391068Z",
     "start_time": "2020-02-25T09:42:02.381291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'系统名称=system_01&任务名称=task_01&实例名=case_01&开始时间=2019-02-25 09:03:00&完成时间=2019-02-25 11:44:53.307657&是否业务异常=0&系统异常=0'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = data[0] \n",
    "'&'.join([i[0] + '=' + i[1] for i in list(zip(d.keys(), d.values()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T09:45:52.254996Z",
     "start_time": "2020-02-25T09:45:52.232859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'系统名称': 'system_01',\n",
       " '任务名称': 'task_01',\n",
       " '实例名': 'case_01',\n",
       " '开始时间': '2019-02-25 09:03:00',\n",
       " '完成时间': '2019-02-25 11:44:53.307657',\n",
       " '是否业务异常': '0',\n",
       " '系统异常': '0'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'系统名称': 'system_01',\n",
       " '任务名称': 'task_01',\n",
       " '实例名': 'case_02',\n",
       " '开始时间': '2019-02-25 11:44:53.307657',\n",
       " '完成时间': '2019-02-25 15:02:40.222676',\n",
       " '是否业务异常': '0',\n",
       " '系统异常': '0'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'系统名称': 'system_01',\n",
       " '任务名称': 'task_01',\n",
       " '实例名': 'case_03',\n",
       " '开始时间': '2019-02-25 15:02:40.222676',\n",
       " '完成时间': '2019-02-25 17:31:16.250314',\n",
       " '是否业务异常': '0',\n",
       " '系统异常': '0'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in data[:3]:\n",
    "    i \n",
    "    url_args = urlencode(i)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T10:00:41.028949Z",
     "start_time": "2020-02-25T10:00:41.025651Z"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "\n",
    "uriencoded = urllib.parse.quote('/s?wd=无人驾驶',encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T10:34:18.482035Z",
     "start_time": "2020-02-24T10:34:17.424108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apparent_encoding close connection content cookies elapsed encoding headers history is_permanent_redirect is_redirect iter_content iter_lines json links next ok raise_for_status raw reason request status_code text url\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'args': {},\n",
       " 'headers': {'Accept': '*/*',\n",
       "  'Accept-Encoding': 'gzip, deflate',\n",
       "  'Host': 'httpbin.org',\n",
       "  'User-Agent': 'python-requests/2.22.0',\n",
       "  'X-Amzn-Trace-Id': 'Root=1-5e53a6a9-cc6e1fa083b21660fc162020'},\n",
       " 'origin': '222.129.35.237',\n",
       " 'url': 'http://httpbin.org/get'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get('http://httpbin.org/get')\n",
    "print(*[i for i in dir(r) if not i.startswith('_')])\n",
    "r.json()\n",
    "#r.text\n",
    "#r.content\n",
    "cup = requests.get('http://httpbin.org')\n",
    "soup = BeautifulSoup(cup.text, features='html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T04:23:55.216735Z",
     "start_time": "2020-02-24T04:21:45.967427Z"
    }
   },
   "outputs": [],
   "source": [
    "# api-endpoint \n",
    "URL = \"http://maps.googleapis.com/maps/api/geocode/json\"\n",
    "  \n",
    "# location given here \n",
    "location = \"delhi technological university\"\n",
    "  \n",
    "# defining a params dict for the parameters to be sent to the API \n",
    "PARAMS = {'address':location} \n",
    "  \n",
    "# sending get request and saving the response as response object \n",
    "r = requests.get(url = URL, params = PARAMS) \n",
    "  \n",
    "# extracting data in json format \n",
    "data = r.json() \n",
    "  \n",
    "  \n",
    "# extracting latitude, longitude and formatted address  \n",
    "# of the first matching location \n",
    "latitude = data['results'][0]['geometry']['location']['lat'] \n",
    "longitude = data['results'][0]['geometry']['location']['lng'] \n",
    "formatted_address = data['results'][0]['formatted_address'] \n",
    "  \n",
    "# printing the output \n",
    "print(\"Latitude:%s\\nLongitude:%s\\nFormatted Address:%s\"\n",
    "      %(latitude, longitude,formatted_address)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third party library "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [arxivpy](https://github.com/titipata/arxivpy)\n",
    "* [sotawhat](https://github.com/chiphuyen/sotawhat)\n",
    "* [arxiv-checker](https://github.com/adamdempsey90/arxiv-checker)\n",
    "* [arxivscraper](https://github.com/Mahdisadjadi/arxivscraper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T06:40:26.999245Z",
     "start_time": "2019-12-11T06:40:26.972380Z"
    }
   },
   "outputs": [],
   "source": [
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = arxiv.query(id_list=[\"1707.08567\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(paper) == list\n",
    "len(paper)\n",
    "paper[0]\n",
    "\n",
    "for i in paper:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table: search_query field prefixes\n",
    "* prefix\texplanation\n",
    "* ti\tTitle\n",
    "* au\tAuthor\n",
    "* abs\tAbstract\n",
    "* co\tComment\n",
    "* jr\tJournal Reference\n",
    "* cat\tSubject Category\n",
    "* rn\tReport Number\n",
    "* id\tId (use id_list instead)\n",
    "* all\tAll of the above\n",
    "\n",
    "Search the result, access and download. Tidy up the name of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = arxiv.query(id_list=[\"1707.08567\"])[0]\n",
    "arxiv.download(paper)\n",
    "# You can skip the query step if you have the paper info!\n",
    "paper2 = {\"pdf_url\": \"http://arxiv.org/pdf/1707.08567v1\",\n",
    "          \"title\": \"The Paper Title\"}\n",
    "arxiv.download(paper2)\n",
    "\n",
    "def custom_slugify(obj):\n",
    "    return obj.get('id').split('/')[-1]\n",
    "\n",
    "# Download with a specified slugifier function\n",
    "arxiv.download(paper, slugify=custom_slugify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.get('title')\n",
    "paper.get('authors')\n",
    "paper.get('summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = arxiv.query(id_list=[\"1707.08567\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the data of an author "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DH = arxiv.query(search_query=\"au: Dieter Horns\")\n",
    "len(DH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DH[3]['affiliation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 'a'  in DH[3]['affiliation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DH[0]['published'] # date time format yyyy-MM-ddTHH:mm:ssZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DH[0]['authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DH[0]['authors'][0]=='Dieter Horns':\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DHevery in DH: \n",
    "    print(DHevery['title'])\n",
    "    print(DHevery['authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DHpaper = arxiv.query(id_list= [\"1309.3846\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper2 = {\"pdf_url\": \"http://arxiv.org/pdf/1707.08567v1\",\n",
    "          \"title\": \"The Paper Title\"}\n",
    "arxiv.download(paper2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DH = arxiv.query(\n",
    "    search_query=\n",
    "    \"au:D. AND au:Horns AND (cat:astro-ph OR cat:hep-ph OR cat:hep-ex OR cat:id_list=physics.ins-det OR cat:astro-ph.HE OR cat:astro-ph.IM OR cat:astro-ph.CO)\",\n",
    "    max_results=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DHevery in DH:\n",
    "    everyitem = {\"pdf_url\": DHevery[\"pdf_url\"], \"title\": DHevery[\"title\"]}\n",
    "    arxiv.download(everyitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DH_index.md', 'w') as the_file:\n",
    "    # the_file.write('## Dieter Horns as First author\\n')\n",
    "    for DHevery in DH:\n",
    "        if DHevery['authors'][0] == 'Dieter Horns':\n",
    "            # if 'University of Hamburg'  in DHevery['affiliation']:\n",
    "            # if len(DHevery['authors']) < 4:\n",
    "            the_file.write('* **Title:** ' + DHevery[\"title\"] + '\\n')\n",
    "            the_file.write('\\n')\n",
    "            the_file.write('  **Published at:** ' + DHevery['published'] +\n",
    "                           '\\n')\n",
    "            the_file.write('\\n')\n",
    "            the_file.write('  **pdf_url:** ' + DHevery['pdf_url'] + '\\n')\n",
    "            the_file.write('\\n')\n",
    "            the_file.write('  **Summary:** ' + DHevery[\"summary\"] + '\\n')\n",
    "    the_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv DH_index.md *.pdf ~/Documents/GammaRay/DieterHorns/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can draw the content of summary from the retrieved data, then read the summary and find the interesting paper and download it with the help of its `pdf_url`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to determine the author is the only one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DH = arxiv.query(search_query=\"au:Dieter Horns\",\n",
    "                 max_results=50)  \n",
    "DH[26]['authors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DH = arxiv.query(search_query=\"au:D. AND au:Horns AND cat:astro-ph \", max_results= 50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`arxiv.query` works less satisfied than `arxiv.download`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the content between a time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DH[0]['published'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dateutil.parser.parse('2008-09-26T01:51:42.000Z')\n",
    "print(d.strftime('%m/%d/%Y'))  #==> '09/26/2008'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateutil.parser.parse(DH[0]['published']).strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the data using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the [result](https://arxiv.org/search/?query=+Dieter+Horns&searchtype=author&abstracts=show&order=-announced_date_first&size=50&start=50) from manually search on arxiv, the result is well displayed, ordered by announced date."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
