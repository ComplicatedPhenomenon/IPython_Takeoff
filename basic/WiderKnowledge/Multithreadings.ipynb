{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://foofish.net/thread.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrement(n):\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "        \n",
    "start = time.time()\n",
    "decrement(100000000)\n",
    "cost = time.time() - start\n",
    "cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "t1 = threading.Thread(target=decrement, args=[50000000])\n",
    "t2 = threading.Thread(target=decrement, args=[50000000])\n",
    "\n",
    "t1.start() # 启动线程，执行任务\n",
    "t2.start() # 同上\n",
    "\n",
    "t1.join() # 主线程阻塞，直到t1执行完成，主线程继续往后执行\n",
    "t2.join() # 同上\n",
    "\n",
    "cost = time.time() - start\n",
    "cost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**是什么原因导致多线程不快反慢的呢**\n",
    "\n",
    "原因就在于 GIL ，在 Cpython 解释器（Python语言的主流解释器）中，有一把全局解释锁（Global Interpreter Lock），在解释器解释执行 Python 代码时，先要得到这把锁，意味着，任何时候只可能有一个线程在执行代码，其它线程要想获得 CPU 执行代码指令，就必须先获得这把锁，如果锁被其它线程占用了，那么该线程就只能等待，直到占有该锁的线程释放锁才有执行代码指令的可能。\n",
    "    \n",
    "因此，这也就是为什么两个线程一起执行反而更加慢的原因，因为同一时刻，只有一个线程在运行，其它线程只能等待，即使是多核CPU，也没办法让多个线程「并行」地同时执行代码，只能是交替执行，因为多线程涉及到上线文切换、锁机制处理（获取锁，释放锁等），所以，多线程执行不快反慢。\n",
    "\n",
    "**什么时候 GIL 被释放呢？**\n",
    "\n",
    "当一个线程遇到 I/O 任务时，将释放GIL。计算密集型（CPU-bound）线程执行 100 次解释器的计步（ticks）时（计步可粗略看作 Python 虚拟机的指令），也会释放 GIL。可以通过 sys.setcheckinterval()设置计步长度，sys.getcheckinterval() 查看计步长度。相比单线程，这些多是多线程带来的额外开销\n",
    "\n",
    "**CPython 解释器为什么要这样设计？**\n",
    "\n",
    "多线程是为了适应现代计算机硬件高速发展充分利用多核处理器的产物，通过多线程使得 CPU 资源可以被高效利用起来，Python 诞生于1991年，那时候硬件配置远没有今天这样豪华，现在一台普通服务器32核64G内存都不是什么司空见惯的事，但是多线程有个问题，怎么解决共享数据的同步、一致性问题，因为，对于多个线程访问共享数据时，可能有两个线程同时修改一个数据情况，如果没有合适的机制保证数据的一致性，那么程序最终导致异常，所以，Python之父就搞了个全局的线程锁，不管你数据有没有同步问题，反正一刀切，上个全局锁，保证数据安全。这也就是多线程鸡肋的原因，因为它没有细粒度的控制数据的安全，而是用一种简单粗暴的方式来解决。\n",
    "\n",
    "这种解决办法放在90年代，其实是没什么问题的，毕竟，那时候的硬件配置还很简陋，单核 CPU 还是主流，多线程的应用场景也不多，大部分时候还是以单线程的方式运行，单线程不要涉及线程的上下文切换，效率反而比多线程更高（在多核环境下，不适用此规则）。所以，采用 GIL 的方式来保证数据的一致性和安全，未必不可取，至少在当时是一种成本很低的实现方式。\n",
    "\n",
    "**那么把 GIL 去掉可行吗？**\n",
    "\n",
    "还真有人这么干多，但是结果令人失望，在1999年Greg Stein 和Mark Hammond 两位哥们就创建了一个去掉 GIL 的 Python 分支，在所有可变数据结构上把 GIL 替换为更为细粒度的锁。然而，做过了基准测试之后，去掉GIL的 Python 在单线程条件下执行效率将近慢了2倍。\n",
    "\n",
    "Python之父表示：基于以上的考虑，去掉GIL没有太大的价值而不必花太多精力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.liaoxuefeng.com/wiki/1016959663602400/1017629247922688\n",
    "\n",
    "启动与CPU核心数量相同的N个线程，在4核CPU上可以监控到CPU占用率仅有102%，也就是仅使用了一核。\n",
    "\n",
    "但是用C、C++或Java来改写相同的死循环，直接可以把全部核心跑满，4核就跑到400%，8核就跑到800%，为什么Python不行呢？\n",
    "\n",
    "因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。\n",
    "\n",
    "GIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。\n",
    "\n",
    "所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。\n",
    "\n",
    "不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  `os.fork()` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:New York Times; font-size:1em; color:green;\">\n",
    "    \n",
    "os.fork() works by calling the underlying OS function fork()\n",
    "\n",
    "With the return value of fork() we can decide in which process we are: 0 means that we are in the child process while a positive return value means that we are in the parent process. A negative return value means that an error occurred while trying to fork. \n",
    "    \n",
    "Unix/Linux操作系统提供了一个fork()系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。子进程永远返回0，而父进程返回子进程的ID。这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Process (%s) start...' % os.getpid())\n",
    "\n",
    "# Python的os模块封装了常见的系统调用，其中就包括fork，可以在Python程序中轻松创建子进程\n",
    "pid = os.fork() \n",
    "print('pid = {}, os.getpid={}'.format(pid, os.getpid()))\n",
    "if pid == 0:\n",
    "    print('I am child process (%s) and my parent is %s.' % (os.getpid(), os.getppid()))\n",
    "else:\n",
    "    print('I (%s) just created a child process (%s).' % (os.getpid(), pid))\n",
    "    #print('I (%s) just created a child process (%s).' % (os.getpid(), os.getpid()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "# 子进程要执行的代码\n",
    "def run_proc(name): \n",
    "    print('Run child process {} {} ...'.format(name, os.getpid()))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print('Parent process %s.' % os.getpid())\n",
    "    p = Process(target=run_proc, args=('TEST', ))\n",
    "    print('Child process will start.')\n",
    "    p.start()\n",
    "    p.join()\n",
    "    print('Child process end.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumer():\n",
    "    r = ''\n",
    "    while True:\n",
    "        n = yield r\n",
    "        if not n:\n",
    "            return\n",
    "        print('[CONSUMER] Consuming %s...' % n)\n",
    "        r = '200 OK'\n",
    "\n",
    "def produce(c):\n",
    "    c.send(None)\n",
    "    n = 0\n",
    "    while n < 5:\n",
    "        n = n + 1\n",
    "        print('[PRODUCER] Producing %s...' % n)\n",
    "        r = c.send(n)\n",
    "        print('[PRODUCER] Consumer return: %s' % r)\n",
    "    c.close()\n",
    "\n",
    "c = consumer()\n",
    "produce(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multithreading in Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将进程挂起(Suspend) 而非 阻塞(Block)\n",
    "\n",
    "如果用sleep() 进程将阻塞\n",
    "\n",
    "假设进程下有两个线程 那么这两个线程会继续运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for specific process in htop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import time, random\n",
    "\n",
    "def long_time_task(name):\n",
    "    print('Run task {} ({})...'.format(name, os.getpid()))\n",
    "    start = time.time()\n",
    "    time.sleep(random.random() * 3)\n",
    "    end = time.time()\n",
    "    print('Task %s runs %0.2f seconds.' % (name, (end - start)))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print('Parent process %s.' % os.getpid())\n",
    "    p = Pool(4)\n",
    "    for i in range(5):\n",
    "        p.apply_async(long_time_task, args=(i,))\n",
    "    print('Waiting for all subprocesses done...')\n",
    "    p.close()\n",
    "    p.join()\n",
    "    print('All subprocesses done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Python Multiprocessing: Pool vs Process – Comparative Analysis](https://www.ellicium.com/python-multiprocessing-pool-process/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View more python learning tutorial on my Youtube and Youku channel!!!\n",
    "\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "import multiprocessing as mp\n",
    "import threading as td\n",
    "import time\n",
    "\n",
    "def job(q):\n",
    "    res = 0\n",
    "    for i in range(1000000):\n",
    "        res += i+i**2+i**3\n",
    "    q.put(res) # queue\n",
    "\n",
    "def multicore():\n",
    "    q = mp.Queue()\n",
    "    p1 = mp.Process(target=job, args=(q,))\n",
    "    p2 = mp.Process(target=job, args=(q,))\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    res1 = q.get()\n",
    "    res2 = q.get()\n",
    "    print('multicore:' , res1+res2)\n",
    "\n",
    "def normal():\n",
    "    res = 0\n",
    "    for _ in range(2):\n",
    "        for i in range(1000000):\n",
    "            res += i+i**2+i**3\n",
    "    print('normal:', res)\n",
    "\n",
    "def multithread():\n",
    "    q = mp.Queue()\n",
    "    t1 = td.Thread(target=job, args=(q,))\n",
    "    t2 = td.Thread(target=job, args=(q,))\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    res1 = q.get()\n",
    "    res2 = q.get()\n",
    "    print('multithread:', res1+res2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    st = time.time()\n",
    "    normal()\n",
    "    st1= time.time()\n",
    "    print('normal time:', st1 - st)\n",
    "    multithread()\n",
    "    st2 = time.time()\n",
    "    print('multithread time:', st2 - st1)\n",
    "    multicore()\n",
    "    print('multicore time:', time.time()-st2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进程间通信\n",
    "<span style=\"font-family:New York Times; font-size:1em; color:green;\">\n",
    "Process之间肯定是需要通信的，操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。\n",
    "\n",
    "我们以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import time, random\n",
    "\n",
    "# 写数据进程执行的代码:\n",
    "def write(q):\n",
    "    print('Process to write: %s' % os.getpid())\n",
    "    for value in ['A', 'B', 'C']:\n",
    "        print('Put %s to queue...' % value)\n",
    "        q.put(value)\n",
    "        time.sleep(random.random())\n",
    "\n",
    "# 读数据进程执行的代码:\n",
    "def read(q):\n",
    "    print('Process to read: %s' % os.getpid())\n",
    "    while True:\n",
    "        value = q.get(True)\n",
    "        print('Get %s from queue.' % value)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # 父进程创建Queue，并传给各个子进程：\n",
    "    q = Queue()\n",
    "    pw = Process(target=write, args=(q,))\n",
    "    pr = Process(target=read, args=(q,))\n",
    "    # 启动子进程pw，写入:\n",
    "    pw.start()\n",
    "    # 启动子进程pr，读取:\n",
    "    pr.start()\n",
    "    # 等待pw结束:\n",
    "    pw.join()\n",
    "    # pr进程里是死循环，无法等待其结束，只能强行终止:\n",
    "    pr.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "class WorkerThread(Thread):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        Thread.__init__(self,*args,**kwargs)\n",
    "        self.input_queue=Queue()\n",
    "\n",
    "    def send(self,item):\n",
    "        self.input_queue.put(item)\n",
    "    def close(self):\n",
    "        self.input_queue.put(None)\n",
    "        self.input_queue.join()\n",
    "    def run(self):\n",
    "        while True:\n",
    "            item=self.input_queue.get()\n",
    "            if item is None:\n",
    "                break\n",
    "            #实际开发中，此处应该使用有用的工作代替\n",
    "            print(item)\n",
    "            self.input_queue.task_done()\n",
    "        #完成，指示收到和返回哨兵\n",
    "        self.input_queue.task_done()\n",
    "        return\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    w=WorkerThread()\n",
    "    w.start()\n",
    "    w.send(\"Mark\")\n",
    "    w.send(\"好\")\n",
    "    w.send(\"？\")\n",
    "    w.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `concurrent.futures`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [PYTHON: A quick introduction to the concurrent to the `concurrent.futures`](http://masnun.com/2016/03/29/python-a-quick-introduction-to-the-concurrent-futures-module.html)\n",
    "\n",
    "    The `concurrent.futures` module is part of the standard library which provides a high level API for launching async tasks\n",
    "    \n",
    "* [ThreadPoolExecutor线程池](https://www.jianshu.com/p/b9b3d66aa0be)\n",
    "* [https://realpython.com/python-concurrency/](https://realpython.com/python-concurrency/)\n",
    "* [http://python.jobbole.com/87272/](http://python.jobbole.com/87272/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ThreadPoolExecutor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from time import sleep\n",
    "\n",
    "def return_after_5_secs(message):\n",
    "    sleep(5)\n",
    "    return message\n",
    "\n",
    "pool = ThreadPoolExecutor(3)\n",
    "# pool.submit(func, (func_parameter)) \n",
    "future = pool.submit(return_after_5_secs, (\"hello\")) # submit tasks to the pool we constructed\n",
    "print(future.done()) #  tells us if the future has resolved\n",
    "sleep(5)\n",
    "print(future.done())\n",
    "print(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# 参数times用来模拟网络请求的时间\n",
    "def get_html(times):\n",
    "    time.sleep(times)\n",
    "    print(\"get page {}s finished\".format(times))\n",
    "    return times\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=2)\n",
    "# 通过submit函数提交执行的函数到线程池中，submit函数立即返回，不阻塞\n",
    "task1 = executor.submit(get_html, (3))\n",
    "task2 = executor.submit(get_html, (2))\n",
    "# done方法用于判定某个任务是否完成\n",
    "print(task1.done())\n",
    "# cancel方法用于取消某个任务,该任务没有放入线程池中才能取消成功\n",
    "print(task2.cancel())\n",
    "time.sleep(4)\n",
    "print(task1.done())\n",
    "# result方法可以获取task的执行结果\n",
    "print(task1.result())\n",
    "\n",
    "# 执行结果\n",
    "# False  # 表明task1未执行完成\n",
    "# False  # 表明task2取消失败，因为已经放入了线程池中\n",
    "# get page 2s finished\n",
    "# get page 3s finished\n",
    "# True  # 由于在get page 3s finished之后才打印，所以此时task1必然完成了\n",
    "# 3     # 得到task1的任务返回值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `as_completed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# 参数times用来模拟网络请求的时间\n",
    "def get_html(times):\n",
    "    time.sleep(times)\n",
    "    print(\"get page {}s finished\".format(times))\n",
    "    return times\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=2)\n",
    "urls = [3, 2, 4] # 并不是真的url\n",
    "all_task = [executor.submit(get_html, (url)) for url in urls]\n",
    "\n",
    "for future in as_completed(all_task):\n",
    "    data = future.result()\n",
    "    print(\"in main: get page {}s success\".format(data))\n",
    "\n",
    "# 执行结果\n",
    "# get page 2s finished\n",
    "# in main: get page 2s success\n",
    "# get page 3s finished\n",
    "# in main: get page 3s success\n",
    "# get page 4s finished\n",
    "# in main: get page 4s success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `wait`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:New York Times; font-size:1em; color:green;\">wait方法接收3个参数，等待的任务序列、超时时间以及等待条件。等待条件return_when默认为ALL_COMPLETED，表明要等待所有的任务都结束。可以看到运行结果中，确实是所有任务都完成了，主线程才打印出main。等待条件还可以设置为FIRST_COMPLETED，表示第一个任务完成就停止等待。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED, FIRST_COMPLETED\n",
    "import time\n",
    "\n",
    "# 参数times用来模拟网络请求的时间\n",
    "def get_html(times):\n",
    "    time.sleep(times)\n",
    "    print(\"get page {}s finished\".format(times))\n",
    "    return times\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=2)\n",
    "urls = [3, 2, 4] # 并不是真的url\n",
    "all_task = [executor.submit(get_html, (url)) for url in urls]\n",
    "wait(all_task, return_when=ALL_COMPLETED)\n",
    "print(\"main\")\n",
    "# 执行结果 \n",
    "# get page 2s finished\n",
    "# get page 3s finished\n",
    "# get page 4s finished\n",
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(times):\n",
    "    time.sleep(times)\n",
    "    print(\"get page {}s finished\".format(times))\n",
    "    return times\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=2)\n",
    "urls = [3, 2, 4] # 并不是真的url\n",
    "all_task = [executor.submit(get_html, (url)) for url in urls]\n",
    "wait(all_task, return_when=FIRST_COMPLETED)\n",
    "print(\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57600892/why-is-python-multithreading-in-this-example-so-slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def testThread(num):\n",
    "    num = \"\"\n",
    "    for i in range(500):\n",
    "        num += str(i % 10)\n",
    "        a.write(num)\n",
    "\n",
    "\n",
    "def main():\n",
    "    for i in range(3000):\n",
    "        testThread(i)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    a = open('single.txt', 'w')\n",
    "    main()\n",
    "    print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def testThread(num):\n",
    "    num = \"\"\n",
    "    for i in range(500):\n",
    "        num += str(i % 10)\n",
    "        with global_lock:\n",
    "            a.write(num)\n",
    "\n",
    "\n",
    "def main():\n",
    "    test_list = [x for x in range(3000)]\n",
    "\n",
    "    with ThreadPool(4) as executor:\n",
    "        results = executor.map(testThread, test_list)\n",
    "\n",
    "    # with ThreadPoolExecutor() as executor:\n",
    "    #    results = executor.map(testThread, test_list)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    a = open('multi.txt', 'w')\n",
    "    global_lock = threading.Lock()\n",
    "    main()\n",
    "    print(time.time() - start_time) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/57618697/time-sleep-not-working-as-expected-when-adding-end-to-print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time,threading\n",
    "\n",
    "msg = \"68 111 110 117 116 115 32 97 114 101 32 98 111 109 98 \"\n",
    "msg = [int(x) for x in msg.split()]\n",
    "\n",
    "def print_msg():\n",
    "    for c in msg:\n",
    "        print(chr(c)),time.sleep(0.2)\n",
    "\n",
    "threading.Thread(target=print_msg).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, threading\n",
    "\n",
    "msg = \"68 111 110 117 116 115 32 97 114 101 32 98 111 109 98 \"\n",
    "msg = [int(x) for x in msg.split()]\n",
    "\n",
    "def print_msg():\n",
    "    for c in msg:\n",
    "        print(chr(c), end=\"\", flush=True)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "threading.Thread(target=print_msg).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel computation\n",
    "\n",
    "<span style=\"font-family:New York Times; font-size:1em; color:green;\">\n",
    "    \n",
    "we would want to use the `ProcessPoolExecutor` for CPU intensive tasks. The `ThreadPoolExecutor` is better suited for network operations or I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import threading\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "\n",
    "# called by each thread\n",
    "def get_url(q, url):\n",
    "    q.put(urllib.request.urlopen(url).read())\n",
    "\n",
    "theurls = [\"http://google.com\", \"http://yahoo.com\"]\n",
    "\n",
    "q = queue.Queue()\n",
    "\n",
    "for u in theurls:\n",
    "    t = threading.Thread(target=get_url, args = (q,u))\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "\n",
    "s = q.get()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = [('80407', 'about power supply of opertional amplifier', '11 hours ago'), ('80405', '5V Regulator Power Dissipation', '11 hours ago')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(';'.join(i) for i in Result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClosestPair(arr0):\n",
    "    arr0s = sorted(arr0)\n",
    "    n = len(arr0)\n",
    "    z = []\n",
    "    x = 0 \n",
    "\n",
    "    if n != len(set(arr0s)):\n",
    "        return (\"No repeated elements\")\n",
    "    else: \n",
    "        while x<n-2:\n",
    "            if arr0s[x+1]-arr0s[x] < 20:\n",
    "                if arr0s[x+1]-arr0s[x] < arr0s[x+2]-arr0s[x+1]:\n",
    "                    z.append([arr0s[x], arr0s[x+1]])\n",
    "                    x+=2 \n",
    "                else:\n",
    "                    z.append([arr0s[x+1], arr0s[x+2]])\n",
    "                    x+=3\n",
    "            else:\n",
    "                x+=1 \n",
    "        # from value in z, find the corresponding index in arr0\n",
    "        result_indexes = [[arr0.index(i[0]), arr0.index(i[1])]  for i in z] \n",
    "        # Adjust the index order\n",
    "        for i, j in enumerate(result_indexes):\n",
    "            if j[0]>j[1]:\n",
    "                result_indexes[i] = [j[1], j[0]]\n",
    "\n",
    "        result_value = [[arr0[i[0]], arr0[i[1]]] for i in result_indexes]\n",
    "        return (result_indexes,result_value )\n",
    "\n",
    "arr0 = [40, 55, 190, 80, 175, 187]\n",
    "findClosestPair(arr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr0s = sorted(arr0)\n",
    "n = len(arr0)\n",
    "z = []\n",
    "x = 0 \n",
    "while x<n-2:\n",
    "    if arr0s[x+1]-arr0s[x] < 20:\n",
    "        if arr0s[x+1]-arr0s[x] < arr0s[x+2]-arr0s[x+1]:\n",
    "            z.append([arr0s[x], arr0s[x+1]])\n",
    "            x+=2 \n",
    "        else:\n",
    "            z.append([arr0s[x+1], arr0s[x+2]])\n",
    "            x+=3\n",
    "    else:\n",
    "        x+=1 \n",
    "    result_indexes = [[arr0.index(i[0]), arr0.index(i[1])]  for i in z] \n",
    "\n",
    "    for i, j in enumerate(result_indexes):\n",
    "        if j[0]>j[1]:\n",
    "            result_indexes[i] = [j[1], j[0]]\n",
    "    result_value = [[arr0[i[0]], arr0[i[1]]] for i in result_indexes]\n",
    "print(result_indexes)\n",
    "#[[0, 1], [2, 5]]\n",
    "print(result_value)\n",
    "#[[40, 55], [190, 187]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timed out input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "answer = None\n",
    "\n",
    "def check():\n",
    "    time.sleep(2)\n",
    "    if answer != None:\n",
    "        return\n",
    "    print (\"Too Slow\")\n",
    "\n",
    "Thread(target = check).start()\n",
    "\n",
    "answer = input(\"Input something: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3\n",
    "pw = 'pw'\n",
    "\n",
    "\n",
    "t_end = time.time() + 5  \n",
    "print(\"Inter the pass word\")\n",
    "while time.time() < t_end:\n",
    "    what = input(\":\")\n",
    "    if pw == what:\n",
    "        print(a)\n",
    "        break \n",
    "        \n",
    "    else:\n",
    "        print(\"Wrong, Input again!\")\n",
    "        continue\n",
    "    \n",
    "print(\"Time is up\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        data = eval(input('prompt:'))\n",
    "        print('READ:', data)\n",
    "except EOFError as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
